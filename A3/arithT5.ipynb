{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "\n",
    "# Load the train and validation datasets from Excel files\n",
    "train_file_path = '../ArithOps_Train.xlsx'  # Replace with your train file path\n",
    "validation_file_path = '../ArithOps_Validation.xlsx'  # Replace with your validation file path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.read_excel(train_file_path)\n",
    "validation_df = pd.read_excel(validation_file_path)\n",
    "\n",
    "# Preprocess data: Remove rows with null values in any column\n",
    "train_df = train_df.dropna()\n",
    "validation_df = validation_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.14\n"
     ]
    }
   ],
   "source": [
    "!python3 -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to prepare data (concatenate description and question, and keep equation as target)\n",
    "def prepare_data(df):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        description = row['Description']\n",
    "        question = row['Question']\n",
    "        equation = row['Equation']\n",
    "\n",
    "        # Concatenate description and question as input\n",
    "        inputs.append(f\"{description} {question}\")\n",
    "        targets.append(equation)\n",
    "    \n",
    "    return inputs, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the train and validation datasets\n",
    "train_inputs, train_targets = prepare_data(train_df)\n",
    "val_inputs, val_targets = prepare_data(validation_df)\n",
    "\n",
    "# Tokenize the inputs and targets\n",
    "def tokenize_data(inputs, targets, tokenizer, max_length=128):\n",
    "    input_encodings = tokenizer(inputs, truncation=True, padding=True, max_length=max_length)\n",
    "    target_encodings = tokenizer(targets, truncation=True, padding=True, max_length=max_length)\n",
    "    \n",
    "    return input_encodings, target_encodings\n",
    "\n",
    "# Tokenize train and validation data\n",
    "train_input_encodings, train_target_encodings = tokenize_data(train_inputs, train_targets, tokenizer)\n",
    "val_input_encodings, val_target_encodings = tokenize_data(val_inputs, val_targets, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Custom Dataset class for PyTorch\n",
    "class ArithmeticDataset(Dataset):\n",
    "    def __init__(self, input_encodings, target_encodings):\n",
    "        self.input_encodings = input_encodings\n",
    "        self.target_encodings = target_encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_encodings['input_ids'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_encodings['input_ids'][idx]),\n",
    "            'attention_mask': torch.tensor(self.input_encodings['attention_mask'][idx]),\n",
    "            'labels': torch.tensor(self.target_encodings['input_ids'][idx]),\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ArithmeticDataset(train_input_encodings, train_target_encodings)\n",
    "val_dataset = ArithmeticDataset(val_input_encodings, val_target_encodings)\n",
    "\n",
    "# DataLoader for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = './best_t5_arithmetic_model'  # Path to the trained model\n",
    "# tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "# model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "# Set up optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Function to replace number placeholders with actual numbers\n",
    "def replace_numbers_in_equation(equation, input_numbers):\n",
    "    # Split input numbers into a list\n",
    "    numbers = input_numbers.split()\n",
    "    \n",
    "    # Replace number0, number1, ... with corresponding input numbers\n",
    "    for i, number in enumerate(numbers):\n",
    "        equation = equation.replace(f\"number{i}\", number)\n",
    "    \n",
    "    return equation\n",
    "\n",
    "\n",
    "import operator\n",
    "\n",
    "# Function to evaluate prefix notation\n",
    "def evaluate_prefix(expression):\n",
    "    # Split the expression into tokens\n",
    "    tokens = expression.split()\n",
    "    \n",
    "    # Stack to hold operands\n",
    "    stack = []\n",
    "    \n",
    "    # Define operator functions\n",
    "    ops = {\n",
    "        '+': operator.add,\n",
    "        '-': operator.sub,\n",
    "        '*': operator.mul,\n",
    "        '/': operator.truediv\n",
    "    }\n",
    "    \n",
    "    # Traverse the tokens in reverse (right-to-left)\n",
    "    for token in reversed(tokens):\n",
    "        if token in ops:\n",
    "            # Pop two operands from the stack for the operation\n",
    "            operand1 = stack.pop()\n",
    "            operand2 = stack.pop()\n",
    "            \n",
    "            # Apply the operator and push the result back to the stack\n",
    "            result = ops[token](operand1, operand2)\n",
    "            stack.append(result)\n",
    "        else:\n",
    "            # If it's a number, push it to the stack\n",
    "            stack.append(float(token))  # Convert numbers to float\n",
    "    \n",
    "    # The final result will be the only item left in the stack\n",
    "    return stack[0]\n",
    "\n",
    "# Evaluate the equation by replacing placeholders and using eval\n",
    "def evaluate_equation(equation):\n",
    "    try:\n",
    "        # Safely evaluate the arithmetic expression\n",
    "        return evaluate_prefix(equation)\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating equation: {equation}. Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Accuracy calculation function\n",
    "def calculate_accuracy(predicted_equations, df):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        input_numbers = row['Input Numbers']\n",
    "        true_output = row['Output']\n",
    "        \n",
    "        # Get the predicted equation and replace placeholders with actual numbers\n",
    "        predicted_equation = replace_numbers_in_equation(predicted_equations[i], input_numbers)\n",
    "        predicted_output = evaluate_equation(predicted_equation)\n",
    "        \n",
    "        # Check if the predicted output matches the true output\n",
    "        if predicted_output == true_output:\n",
    "            correct_predictions += 1\n",
    "        \n",
    "        total_predictions += 1\n",
    "    \n",
    "    return correct_predictions / total_predictions\n",
    "\n",
    "# Training loop with model saving and accuracy calculation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 20\n",
    "best_val_loss = float('inf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Training Loss: 0.2740041530132294\n",
      "Epoch 1/20, Validation Loss: 0.4931645542383194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:57<18:09, 57.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 1\n",
      "Validation Accuracy: 25.63%\n",
      "Epoch 2/20, Training Loss: 0.2554258760809898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trishitm/miniconda3/envs/dl-nlp/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Validation Loss: 0.4846912920475006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:53<17:04, 56.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 2\n",
      "Validation Accuracy: 25.63%\n",
      "Epoch 3/20, Training Loss: 0.24131862998008727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trishitm/miniconda3/envs/dl-nlp/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Validation Loss: 0.4744269390191351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [02:50<16:04, 56.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 3\n",
      "Validation Accuracy: 27.14%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {avg_train_loss}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    predicted_equations = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            val_loss += model(input_ids=input_ids, attention_mask=attention_mask, labels=labels).loss.item()\n",
    "\n",
    "            # Convert generated tokens back to equations\n",
    "            predicted_equations.extend([tokenizer.decode(ids, skip_special_tokens=True) for ids in outputs])\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {avg_val_loss}\")\n",
    "\n",
    "    # Save the model if validation loss decreases\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        model.save_pretrained('./best_t5_arithmetic_model')\n",
    "        tokenizer.save_pretrained('./best_t5_arithmetic_model')\n",
    "        print(f\"Model saved at epoch {epoch + 1}\")\n",
    "\n",
    "    # Calculate accuracy after each epoch using validation data\n",
    "    val_accuracy = calculate_accuracy(predicted_equations, validation_df)\n",
    "    print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Save the final model\n",
    "model.save_pretrained('./final_t5_arithmetic_model')\n",
    "tokenizer.save_pretrained('./final_t5_arithmetic_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
